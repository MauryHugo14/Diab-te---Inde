---
title: "Projet - Diabète en Inde"
author: "Hugo Maury"
date: '`r Sys.Date()`'
output: html_document
---

**Contexte**  

Ce jeu de données provient à l'origine de l'Institut national du diabète et des maladies digestives et rénales. L'objectif de ce jeu de données est de prédire diagnostiquement si un patient a ou non le diabète, en fonction de certaines mesures diagnostiques incluses dans le jeu de données. Plusieurs contraintes ont été imposées lors de la sélection de ces instances à partir d'une base de données plus grande. En particulier, toutes les patientes ici sont des femmes d'au moins 21 ans d'origine Pima.

\newpage

# 1. Présentation des données

**Pregnancies** : Nombre de fois enceinte

**Glucose** : Concentration de glucose plasmatique à 2 heures dans un test de tolérance au glucose oral

**BloodPressure** : Tension artérielle diastolique (mm Hg)

**SkinThickness** : Épaisseur du pli cutané au triceps (mm)

**Insulin** : Insuline sérique à 2 heures (mu U/ml)

**BMI** : Indice de masse corporelle (poids en kg / (taille en m)²)

**DiabetesPedigreeFunction** : Fonction de pedigree du diabète

**Age** : Âge (années)

**Outcome** : Variable de classe (0 ou 1) 268 sur 768 sont 1, les autres sont 0


*Objectif*
Construire un modèle d'apprentissage automatique pour prédire avec précision si les patients du jeu de données ont ou non le diabète

\newpage

# 2. Première analyse
```{r, include=FALSE, echo=FALSE}
# ---- Importation des library ----
library(dplyr)
library(ggplot2)
library(gtsummary)

# ---- Importation des données ----
data = read.csv("diabetes.csv", sep=",")

data %>% mutate(Outcome = factor(Outcome,  labels=c("no", "yes"))) -> data

```

Tableau récapitulatif
```{r}
### Tableau récapitulatif
tbl_summary(data, by='Outcome', 
            statistic = list(all_continuous() ~ "{mean} ({median})"))
```

Je vois clairement quelques différences entre les patientes qui ont le diabète et ceux qui ne l'ont pas.
Les patientes ayant le diabète ont géneralement 2 accouchements de plus, plus de glucose dans le sang et plus d'insuline.

Vérifions ces résultats à l'aide d'un premier modèle de régression

```{r}
glm(Outcome ~ ., data=data, family = binomial(link = "logit")) %>%
  tbl_regression(exponentiate = TRUE)
```

Si l'on se concentre sur les p_values,je constate que l'épaisseur de la peau, l'insuline et l'âge ne semble pas avoir d'impacte pour avoir le diabète. 

\newpage

```{r}
# ---- Importation des libraries nécessaires ----
library(caret)
library(ranger)

# ---- Préparation des données ----
set.seed(42)  # Pour la reproductibilité
data$Outcome <- as.factor(data$Outcome)  # Convertir la variable cible en facteur

# Diviser les données en ensemble d'entraînement et de test
trainIndex <- createDataPartition(data$Outcome, p = .8, 
                                  list = FALSE, 
                                  times = 1)
dataTrain <- data[trainIndex, ]
dataTest  <- data[-trainIndex, ]

# ---- Construction du modèle avec ranger ----
rf_model <- ranger(Outcome ~ ., data = dataTrain, importance = 'impurity', num.trees = 100)

# ---- Évaluation du modèle ----
# Prédictions sur l'ensemble de test
predictions <- predict(rf_model, data = dataTest)$predictions

# Matrice de confusion
confusionMatrix(factor(predictions), dataTest$Outcome)

# ---- Importance des variables ----
importance <- rf_model$variable.importance
importance_df <- data.frame(Variable = names(importance), Importance = importance)
importance_df <- importance_df[order(importance_df$Importance, decreasing = TRUE), ]

# Visualiser l'importance des variables
ggplot(importance_df, aes(x = reorder(Variable, Importance), y = Importance)) +
  geom_bar(stat = "identity") +
  coord_flip() +
  labs(title = "Importance des Variables", x = "Variables", y = "Importance")



```

\newpage

# Mon programme
```{r}
library(caret)
library(MASS)
library(car)
```

```{r}
set.seed(12345)
trainIndex = data$Outcome %>% createDataPartition(p=0.7, times=1, list = FALSE)
train = data[trainIndex,]
test = data[-trainIndex,]

model1 = glm(Outcome ~., data=train, family=binomial(link="logit"))
Anova(model1, type="II", test="LR")
model2 = stepAIC(model1, direction = "both", k = 10, trace=TRUE)

# Modele final
summary(model2)
```

\newpage

```{r}
# Courbe de sensibilité et de spécificité
library(ROCR)
proba = predict(model2, newdata=train, type="response")
pred <- prediction(proba, train$Outcome)
perf2 = performance(pred, measure = "sens", x.measure = "spec")

data2 = data.frame(Sensibility = perf2@y.values[[1]], Specificity = perf2@x.values[[1]], Cutoff = perf2@alpha.values[[1]])
(opt2 = data2[which.min(abs(data2$Sensibility - data2$Specificity)),])

ggplot(data=data2)+
  geom_line(aes(x=Cutoff, y=Sensibility, color="1"), size=1.3)+
  geom_line(aes(x=Cutoff, y=Specificity, color="2"), size=1.3)+
  labs(title="Courbe de sensibilité et de spécificité", x="Cutoff", y="Value")+
  scale_color_discrete(name = "", labels = c("Sensitivity", "Specificity"))+
  geom_vline(aes(xintercept=opt2$Cutoff), lty=2)+
  annotate(geom = "text", x=0.25, y=0.80, label=paste("Seuil : ", (opt2$Cutoff)))
```

```{r}
# Prévision
probability = model2 %>% predict(newdata=test, type="response")
predicted = ifelse(probability > opt2$Cutoff, "yes", "no")
predicted = factor(predicted)
# Matrice de confusion
confusionMatrix(data=predicted, reference=test$Outcome, positive = "yes")
```



