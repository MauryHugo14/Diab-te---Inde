# Importation des library
data = read.csv("diabetes.csv", sep=",")
summary(data)
# Importation des library
library(dplyr)
library(ggplot2)
data %>% group_by(Outcome)
data %>% group_by(Outcome) %>% summarise(Mean=mean())
data %>% group_by(Outcome) %>% summarise(Mean=mean(n()))
data %>% group_by(Outcome) %>% summarise(Mean=mean(Age))
plot(Age, Outcome)
plot(Age, Outcome, data=data)
plot(Age, Outcome, dataset=data)
plot(data$Age, data$Outcome)
plot(data$Age)
plot(data$Age, colors(Outcome))
plot(data$Age, colors(data$Outcome))
ggplot(data, aes(x=Age, color=Outcome))
ggplot(data, aes(x=Age, color=Outcome)) %>%
geom_point()
ggplot(data, aes(x=Age, color=Outcome)) +
geom_point()
ggplot(data, aes(x=Age, y=Glucose, color=as.factor(Outcome), group = Outcome) +
geom_point()
)
ggplot(data, aes(x=Age, y=Glucose, color=as.factor(Outcome), group = Outcome)) +
geom_point()
ggplot(data, aes(x=Age, y=Glucose, color=as.factor(Outcome), group = Outcome)) +
geom_point() +
labs(title = "Concentration de glucose en fonction de l'âge", x = "Age", y = "Concentration de glucose", color = "Diabète")+
theme_minimal()
library(gtsummary)
### Tableau récapitulatif
tbl_summary(data, by='Outcome')
?tbl_summary
### Tableau récapitulatif
tbl_summary(data, by='Outcome',
label = list(Outcome ~ .),
statistic = list(all_continuous() ~ "{mean}"))
### Tableau récapitulatif
tbl_summary(data, by='Outcome',
label = list(Outcome ~ "Diabète"),
statistic = list(all_continuous() ~ "{mean}"))
### Tableau récapitulatif
tbl_summary(data, by='Outcome',
statistic = list(all_continuous() ~ "{mean}"))
### Tableau récapitulatif
tbl_summary(data, by='Outcome',
statistic = list(all_continuous() ~ "{mean} ({median})"))
### Tableau récapitulatif
tbl_summary(data, by='Outcome',
statistic = list(all_continuous() ~ "{mean} ({median})"))
glm(Outcome ~ ., data=data, family = binomial(link = "logit")) %>%
tbl_regression(exponentiate = TRUE)
glm(Outcome ~ ., data=data, family = binomial(link = "logit")) %>%
tbl_regression(exponentiate = TRUE)
glm(Outcome ~ ., data=data, family = binomial(link = "logit"))
glm(Outcome ~ ., data=data, family = binomial(link = "logit")) %>%
tbl_regression(exponentiate = False)
glm(Outcome ~ ., data=data, family = binomial(link = "logit")) %>%
tbl_regression()
glm(Outcome ~ ., data=data, family = binomial(link = "logit")) %>%
tbl_regression()
glm(Outcome ~ ., data=data, family = binomial(link = "logit")) %>%
tbl_regression()
glm(Outcome ~ ., data=data, family = binomial(link = "logit")) %>%
tbl_regression(exponentiate = True)
glm(Outcome ~ ., data=data, family = binomial(link = "logit")) %>%
tbl_regression(exponentiate = TRUE)
# ---- Importation des library ----
library(dplyr)
library(ggplot2)
library(gtsummary)
# ---- Importation des données ----
data = read.csv("diabetes.csv", sep=",")
### Tableau récapitulatif
tbl_summary(data, by='Outcome',
statistic = list(all_continuous() ~ "{mean} ({median})"))
glm(Outcome ~ ., data=data, family = binomial(link = "logit")) %>%
tbl_regression(exponentiate = TRUE)
library(caret)
model1 = glm(Outcome ~., data=data, family=binomial(link="logit"))
model1
Anova(model1, type="II", test="LR")
library(MASS)
Anova(model1, type="II", test="LR")
library(car)
Anova(model1, type="II", test="LR")
Anova(model2, type="II", test="LR")
model2 = stepAIC(model1, direction = "both", k = 2, trace=FALSE)
Anova(model2, type="II", test="LR")
model2 = update(model2, ~.-Insulin)
Anova(model2, type="II", test="LR")
model2 = update(model2, ~.-Age)
Anova(model2, type="II", test="LR")
# Modele final
summary(model2)
set.seed(12345)
trainIndex = data$Outcome %>% createDataPartition(p=0.7, times=1, list = FALSE)
# ---- Importation des library ----
library(dplyr)
library(ggplot2)
library(gtsummary)
# ---- Importation des données ----
data = read.csv("diabetes.csv", sep=",")
set.seed(12345)
trainIndex = data$Outcome %>% createDataPartition(p=0.7, times=1, list = FALSE)
train = data[trainIndex,]
test = data[-trainIndex,]
model1 = glm(Outcome ~., data=data, family=binomial(link="logit"))
Anova(model1, type="II", test="LR")
model2 = stepAIC(model1, direction = "both", k = 2, trace=FALSE)
Anova(model2, type="II", test="LR")
model2 = update(model2, ~.-Insulin)
Anova(model2, type="II", test="LR")
model2 = update(model2, ~.-Age)
Anova(model2, type="II", test="LR")
# Modele final
summary(model2)
set.seed(12345)
trainIndex = data$Outcome %>% createDataPartition(p=0.7, times=1, list = FALSE)
train = data[trainIndex,]
test = data[-trainIndex,]
model1 = glm(Outcome ~., data=train, family=binomial(link="logit"))
Anova(model1, type="II", test="LR")
model2 = stepAIC(model1, direction = "both", k = 2, trace=FALSE)
Anova(model2, type="II", test="LR")
model2 = update(model2, ~.-Insulin)
Anova(model2, type="II", test="LR")
model2 = update(model2, ~.-Age)
Anova(model2, type="II", test="LR")
# Modele final
summary(model2)
model1 = glm(Outcome ~., data=train, family=binomial(link="logit"))
Anova(model1, type="II", test="LR")
model2 = stepAIC(model1, direction = "both", k = 2, trace=FALSE)
Anova(model2, type="II", test="LR")
model1 = glm(Outcome ~., data=train, family=binomial(link="logit"))
Anova(model1, type="II", test="LR")
model2 = stepAIC(model1, direction = "both", k = 2, trace=FALSE)
Anova(model2, type="II", test="LR")
model2 = update(model2, ~.-SkinThickness)
Anova(model2, type="II", test="LR")
model1 = glm(Outcome ~., data=train, family=binomial(link="logit"))
Anova(model1, type="II", test="LR")
model2 = stepAIC(model1, direction = "both", k = 2, trace=FALSE)
Anova(model2, type="II", test="LR")
model1 = glm(Outcome ~., data=train, family=binomial(link="logit"))
Anova(model1, type="II", test="LR")
model2 = stepAIC(model1, direction = "both", k = 4, trace=FALSE)
Anova(model2, type="II", test="LR")
model1 = glm(Outcome ~., data=train, family=binomial(link="logit"))
Anova(model1, type="II", test="LR")
model2 = stepAIC(model1, direction = "both", k = 10, trace=FALSE)
model2 = stepAIC(model1, direction = "both", k = 10, trace=FALSE)
Anova(model2, type="II", test="LR")
model1 = glm(Outcome ~., data=train, family=binomial(link="logit"))
Anova(model1, type="II", test="LR")
model2 = stepAIC(model1, direction = "both", k = 10, trace=TRUE)
# Modele final
summary(model2)
# Courbe de sensibilité et de spécificité
library(ROCR)
proba = predict(model2, newdata=train, type="response")
pred <- prediction(proba, train$Outcome)
perf2 = performance(pred, measure = "sens", x.measure = "spec")
data2 = data.frame(Sensibility = perf2@y.values[[1]], Specificity = perf2@x.values[[1]], Cutoff = perf2@alpha.values[[1]])
(opt2 = data2[which.min(abs(data2$Sensibility - data2$Specificity)),])
ggplot(data=data2)+
geom_line(aes(x=Cutoff, y=Sensibility, color="1"), size=1.3)+
geom_line(aes(x=Cutoff, y=Specificity, color="2"), size=1.3)+
labs(title="Courbe de sensibilité et de spécificité", x="Cutoff", y="Value")+
scale_color_discrete(name = "", labels = c("Sensitivity", "Specificity"))+
geom_vline(aes(xintercept=opt2$Cutoff), lty=2)+
annotate(geom = "text", x=0.25, y=0.80, label=paste("Seuil : ", (opt2$Cutoff)))
# Prévision
probability = model2 %>% predict(newdata=test, type="response")
predicted = ifelse(probability > opt2$Cutoff, "yes", "no")
predicted = factor(predicted)
# Matrice de confusion
confusionMatrix(data=predicted, reference=test$Outcome, positive = "yes")
probability
predicted
predicted
test$Outcome
# Matrice de confusion
confusionMatrix(data=predicted, reference=test$Outcome, positive = 1)
data %>% mutate(Outcome = factor(Outcome,  labels=c("no", "yes"))) -> data
set.seed(12345)
trainIndex = data$Outcome %>% createDataPartition(p=0.7, times=1, list = FALSE)
train = data[trainIndex,]
test = data[-trainIndex,]
model1 = glm(Outcome ~., data=train, family=binomial(link="logit"))
Anova(model1, type="II", test="LR")
model2 = stepAIC(model1, direction = "both", k = 10, trace=TRUE)
# Modele final
summary(model2)
# Courbe de sensibilité et de spécificité
library(ROCR)
proba = predict(model2, newdata=train, type="response")
pred <- prediction(proba, train$Outcome)
perf2 = performance(pred, measure = "sens", x.measure = "spec")
data2 = data.frame(Sensibility = perf2@y.values[[1]], Specificity = perf2@x.values[[1]], Cutoff = perf2@alpha.values[[1]])
(opt2 = data2[which.min(abs(data2$Sensibility - data2$Specificity)),])
ggplot(data=data2)+
geom_line(aes(x=Cutoff, y=Sensibility, color="1"), size=1.3)+
geom_line(aes(x=Cutoff, y=Specificity, color="2"), size=1.3)+
labs(title="Courbe de sensibilité et de spécificité", x="Cutoff", y="Value")+
scale_color_discrete(name = "", labels = c("Sensitivity", "Specificity"))+
geom_vline(aes(xintercept=opt2$Cutoff), lty=2)+
annotate(geom = "text", x=0.25, y=0.80, label=paste("Seuil : ", (opt2$Cutoff)))
# Prévision
probability = model2 %>% predict(newdata=test, type="response")
predicted = ifelse(probability > opt2$Cutoff, "yes", "no")
predicted = factor(predicted)
# Matrice de confusion
confusionMatrix(data=predicted, reference=test$Outcome, positive = 1)
# Matrice de confusion
confusionMatrix(data=predicted, reference=test$Outcome, positive = "yes")
